{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway #1. Defense performance is sensitive to the purity of the base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minzhou/anaconda3/envs/metasift/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models import PreActResNet18\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from meta_sift import *\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "device = 'cuda'\n",
    "torch.cuda.set_device(0)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a poisoned Model\n",
    "poisoned_model = VGG('small_VGG16')\n",
    "poisoned_model.load_state_dict(torch.load('./checkpoints/gtsrb_tar38_badnets.pth', map_location=\"cuda\"))\n",
    "poisoned_model = poisoned_model.cuda()\n",
    "\n",
    "# Load the ASR evaluation testset\n",
    "data_transform = transforms.Compose([transforms.ToTensor(),])\n",
    "train_path = './dataset/gtsrb_dataset.h5'\n",
    "testset = h5_dataset(train_path, False, None)\n",
    "asr_test = posion_image_all2one(testset, list(np.where(np.array(testset.targets)!=38)[0]), 38, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Poison Model ASR: 96.793%\n"
     ]
    }
   ],
   "source": [
    "# Get ASR\n",
    "print('Original Poison Model ASR: %.3f%%' % (get_results(poisoned_model, asr_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the poisoned train dataset\n",
    "trainset = h5_dataset(train_path, True, None)\n",
    "train_poi_set, poi_idx = poi_dataset(trainset, poi_methond=\"badnets\", transform=data_transform, poi_rates=0.33,random_seed=0, tar_lab=38)\n",
    "clean_validset = get_validset(train_poi_set, poi_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\n",
      "Round: 1\n",
      "Round: 2\n",
      "Round: 3\n",
      "Round: 4\n",
      "I-BAU (clean base set) Cleaned Model ASR: 11.409%\n"
     ]
    }
   ],
   "source": [
    "from ibau import IBAU\n",
    "# Import IBAU to clean the model\n",
    "acctest = h5_dataset(train_path, False, data_transform)\n",
    "cleaned_model = IBAU(copy.deepcopy(poisoned_model), clean_validset)\n",
    "print('I-BAU (clean base set) Cleaned Model ASR: %.3f%%' % (get_results(copy.deepcopy(cleaned_model), asr_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\n",
      "Round: 1\n",
      "Round: 2\n",
      "Round: 3\n",
      "Round: 4\n",
      "I-BAU (poisoned base set) Cleaned Model ASR: 73.769%\n"
     ]
    }
   ],
   "source": [
    "# Ibau with poisoned base set, only 8 poisoned sample in 1000 base set.\n",
    "poi_base_set = get_validset(train_poi_set, poi_idx, 1000, 8)\n",
    "cleaned_model_dirty = IBAU(copy.deepcopy(poisoned_model), poi_base_set)\n",
    "\n",
    "print('I-BAU (poisoned base set) Cleaned Model ASR: %.3f%%' % (get_results(copy.deepcopy(cleaned_model_dirty), asr_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway #2.Existing automated methods fail to identify a clean subset with high enough precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dc import DCM\n",
    "dc_idx = DCM(train_poi_set, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\n",
      "Round: 1\n",
      "Round: 2\n",
      "Round: 3\n",
      "Round: 4\n",
      "I-BAU (DCM base set) Cleaned Model ASR: 70.079%\n"
     ]
    }
   ],
   "source": [
    "cleaned_model_dirty = IBAU(copy.deepcopy(poisoned_model), torch.utils.data.Subset(train_poi_set, dc_idx))\n",
    "\n",
    "\n",
    "print('I-BAU (DCM base set) Cleaned Model ASR: %.3f%%' % (get_results(copy.deepcopy(cleaned_model_dirty), asr_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCR for DCM is: 33.885%\n"
     ]
    }
   ],
   "source": [
    "print('NCR for DCM is: %.3f%%' % get_NCR(train_poi_set, poi_idx, dc_idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway #3. Meta-Sift can obtain a clean subset under poison situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # Number of classes in sifting dafast\n",
    "    num_classes = 43\n",
    "    # Number of sifter\n",
    "    num_sifter = 5\n",
    "    # Number of sifting epoch\n",
    "    res_epochs = 1\n",
    "    # Number of warm epoch before sifting start\n",
    "    warmup_epochs = 1\n",
    "    # Batch size in sifting\n",
    "    batch_size = 128\n",
    "    # Number of workers in dataloader\n",
    "    num_workers = 16\n",
    "    # Learning rate for vent\n",
    "    v_lr = 0.0005\n",
    "    # Virtual update learning rate\n",
    "    meta_lr = 0.1\n",
    "    # Top k will be select to compute gradient\n",
    "    top_k = 15\n",
    "    # Learning rate for gradinet selection model\n",
    "    go_lr = 1e-1\n",
    "    # Number of activation for gradinet selection model\n",
    "    num_act = 4\n",
    "    momentum = 0.9\n",
    "    nesterov = True\n",
    "    # Random seed\n",
    "    random_seed = 0\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training sifter number: 0-----------\n",
      "Warmup Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:33<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training sifter number: 1-----------\n",
      "Warmup Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training sifter number: 2-----------\n",
      "Warmup Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training sifter number: 3-----------\n",
      "Warmup Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:33<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training sifter number: 4-----------\n",
      "Warmup Epoch 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "307it [00:02, 120.19it/s]                         \n",
      "307it [00:02, 120.79it/s]                         \n",
      "307it [00:02, 120.07it/s]                         \n",
      "307it [00:02, 120.38it/s]                         \n",
      "307it [00:02, 120.58it/s]                         \n"
     ]
    }
   ],
   "source": [
    "meta_sift_idx = meta_sift(args, train_poi_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\n",
      "Round: 1\n",
      "Round: 2\n",
      "Round: 3\n",
      "Round: 4\n",
      "I-BAU (meta sift base set) Cleaned Model ASR: 8.951%\n"
     ]
    }
   ],
   "source": [
    "cleaned_model_meta_sitf = IBAU(copy.deepcopy(poisoned_model), torch.utils.data.Subset(train_poi_set, meta_sift_idx))\n",
    "\n",
    "print('I-BAU (meta sift base set) Cleaned Model ASR: %.3f%%' % (get_results(copy.deepcopy(cleaned_model_meta_sitf), asr_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCR for Meta Sift is: 0.000%\n"
     ]
    }
   ],
   "source": [
    "# NCR for meta_sift\n",
    "print('NCR for Meta Sift is: %.3f%%' % get_NCR(train_poi_set, poi_idx, meta_sift_idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b8be34f2a64f133f414bd034f75b72cc1c8d29070f6944ffe8bd65ff6cd5b9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
